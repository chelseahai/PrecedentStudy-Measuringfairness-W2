
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Contextual Timeline | Fairness, Explained</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <header>
    <h1>Contextual Timeline</h1>
    <nav>
      <a href="index.html">Back to Home</a>
    </nav>
  </header>
  <main>
    <section>
      <h2>Historical Context</h2>
      <p>“Measuring Fairness” was released by Google's PAIR team in 2018, during a period of intense public scrutiny over algorithmic decision-making. The project aimed to address misunderstandings and surface tensions in competing definitions of fairness in machine learning.</p>
      <p>This came shortly after high-profile events such as:</p>
      <ul>
        <li><strong>2016:</strong> ProPublica's report on racial bias in the COMPAS algorithm</li>
        <li><strong>2018:</strong> Research by Joy Buolamwini and Timnit Gebru showing facial recognition disparities</li>
        <li><strong>2018:</strong> Rise of explainable AI (XAI) initiatives</li>
      </ul>
    </section>
    <section>
      <h2>Authorial Intent</h2>
      <p>The authors sought to clarify the inherent trade-offs in algorithmic fairness. By making the definitions interactive, they emphasized that fairness is not a solved problem but a set of ethical decisions.</p>
    </section>
    <section>
      <h2>Intended Audience</h2>
      <ul>
        <li>Machine learning practitioners</li>
        <li>Students and educators in data ethics</li>
        <li>Policy-makers and journalists</li>
        <li>General public with interest in AI</li>
      </ul>
    </section>
  </main>
</body>
</html>
